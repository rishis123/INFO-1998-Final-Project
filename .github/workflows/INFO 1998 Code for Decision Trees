#Creator: Rishi Shah, Cornell University

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score
from sklearn import preprocessing
from sklearn.metrics import r2_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import tree
from sklearn import datasets
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import KFold

df = pd.read_csv("/Users/rishishah/Downloads/archive/diabetes_012_health_indicators_BRFSS2015.csv")
#print(df) # note: this is the CSV file where Diabetes_012 has 0 for no-diabetes, 1 for pre-diabetes, and 2 for diabetes

X = df.drop("Diabetes_012", axis='columns')  # Features
Y = df['Diabetes_012']  # Target variable
#Test-train split our data (note we are using 0,1,2 diabetes classification unlike logistic regression
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1998)

best_depth = 1  # Keep track of depth that produces tree with highest accuracy
best_accuracy = 0  # The best accuracy from a given tree
for k in range(1, 60):
    #Create and fit a model of depth k --> want to find best depth so iterate over 1 to 59
    model = tree.DecisionTreeClassifier(max_depth=k)

    model.fit(X_train, Y_train)

    # TODO store the predictions for the test set
    pred_test = model.predict(X_test)

    # Find the accuracy of the model's predictions (pred_test)
    # compared to the actual samples, and score the accuracy in acc_test.
    acc_test = accuracy_score(Y_test, pred_test)

    # Compare the accuracy found with the best current depth/accuracy found and update if necessary

    if best_accuracy < acc_test:
        best_accuracy = acc_test
        best_depth = k

#print(best_accuracy)
#print(best_depth) --> console results: 5, but can change from run to next (store best_depth as variable and use for cross validation)
'''''''''''
Yielded 
best_accuracy = 0.8487464522232734, but can change from run to next
best_depth = 5, but can change from run to next (store best_depth as variable and use for cross validation)
'''


#We use 5-fold cross validation to yield average accuracy at our best depth
kf = KFold(n_splits = 5) # number of folds -- default value
totAccuracy = 0

# Optimal model creation
model = tree.DecisionTreeClassifier(max_depth=best_depth)  # using the best_depth from previous part
# store model outside for space storage within cross-validation, as well as for feature importance below



for train_index, test_index in kf.split(X): # within incX, we split into our train and test data based on our desired folds
    # TODO: define X_train, X_test, Y_train, Y_test
    X_train = X.iloc[train_index]
    Y_train = Y.iloc[train_index] # want same corresponding training indices
    X_test = X.iloc[test_index]
    Y_test = Y.iloc[test_index] # same for testing

    #Fit model
    model.fit(X_train, Y_train)

    # Yield Accuracy score, add to totAccuracy (sum of all folds' accuracy)
    accuracyEach = accuracy_score(Y_test, model.predict(X_test))
    totAccuracy += accuracyEach
avgAccuracy = totAccuracy / 5 # average accuracy across all folds
print(avgAccuracy)

'''''''''
Yielded
0.8475126143172501 as average accuracy across all 5 folds
'''

# Get feature importances
feature_importances = model.feature_importances_

# Map feature names to their importance scores
feature_importance_dict = dict(zip(X.columns, feature_importances))

# Sort features by importance in descending order
sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)

print(sorted_features) # yields weights of each feature, summing to 1

#For visualization's sake, we can now unzip the sorted dictionary into each feature's name and importance
feature_names, importances = zip(*sorted_features)

# Plotting each feature by importance in a bar-graph
plt.figure(figsize=(10, 6))
plt.barh(range(len(feature_names)), importances, align='center') #plot each bar -- each feature's names with corresponding importance
plt.yticks(range(len(feature_names)), feature_names) #names each bar with feature's name
plt.xlabel('Feature Importance')
plt.title("Decision Trees' Relative Feature Importance for Diabetes Diagnosis prediction")
plt.show()
